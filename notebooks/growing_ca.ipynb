{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Growing Neural Cellular Automata",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28S76DVlfCMZ"
      },
      "source": [
        "# Growing Neural Cellular Automata\n",
        "\n",
        "This notebook contains code to reproduce experiments and figures for the [\"Growing Neural Cellular Automata\"](http://distill.pub/2020/growing-ca) article.\n",
        "\n",
        "Copyright 2020 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5wi_r4gyzFr"
      },
      "source": [
        "#@title Imports and Notebook Utilities\n",
        "%tensorflow_version 2.x\n",
        "\n",
        "import os\n",
        "import io\n",
        "import PIL.Image, PIL.ImageDraw\n",
        "import base64\n",
        "import zipfile\n",
        "import json\n",
        "import requests\n",
        "import numpy as np\n",
        "import matplotlib.pylab as pl\n",
        "import glob\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from IPython.display import Image, HTML, clear_output\n",
        "import tqdm\n",
        "\n",
        "import os\n",
        "os.environ['FFMPEG_BINARY'] = 'ffmpeg'\n",
        "import moviepy.editor as mvp\n",
        "from moviepy.video.io.ffmpeg_writer import FFMPEG_VideoWriter\n",
        "clear_output()\n",
        "\n",
        "def np2pil(a):\n",
        "  if a.dtype in [np.float32, np.float64]:\n",
        "    a = np.uint8(np.clip(a, 0, 1)*255)\n",
        "  return PIL.Image.fromarray(a)\n",
        "\n",
        "def imwrite(f, a, fmt=None):\n",
        "  a = np.asarray(a)\n",
        "  if isinstance(f, str):\n",
        "    fmt = f.rsplit('.', 1)[-1].lower()\n",
        "    if fmt == 'jpg':\n",
        "      fmt = 'jpeg'\n",
        "    f = open(f, 'wb')\n",
        "  np2pil(a).save(f, fmt, quality=95)\n",
        "\n",
        "def imencode(a, fmt='jpeg'):\n",
        "  a = np.asarray(a)\n",
        "  if len(a.shape) == 3 and a.shape[-1] == 4:\n",
        "    fmt = 'png'\n",
        "  f = io.BytesIO()\n",
        "  imwrite(f, a, fmt)\n",
        "  return f.getvalue()\n",
        "\n",
        "def im2url(a, fmt='jpeg'):\n",
        "  encoded = imencode(a, fmt)\n",
        "  base64_byte_string = base64.b64encode(encoded).decode('ascii')\n",
        "  return 'data:image/' + fmt.upper() + ';base64,' + base64_byte_string\n",
        "\n",
        "def imshow(a, fmt='jpeg'):\n",
        "  display(Image(data=imencode(a, fmt)))\n",
        "\n",
        "def tile2d(a, w=None):\n",
        "  a = np.asarray(a)\n",
        "  if w is None:\n",
        "    w = int(np.ceil(np.sqrt(len(a))))\n",
        "  th, tw = a.shape[1:3]\n",
        "  pad = (w-len(a))%w\n",
        "  a = np.pad(a, [(0, pad)]+[(0, 0)]*(a.ndim-1), 'constant')\n",
        "  h = len(a)//w\n",
        "  a = a.reshape([h, w]+list(a.shape[1:]))\n",
        "  a = np.rollaxis(a, 2, 1).reshape([th*h, tw*w]+list(a.shape[4:]))\n",
        "  return a\n",
        "\n",
        "def zoom(img, scale=4):\n",
        "  img = np.repeat(img, scale, 0)\n",
        "  img = np.repeat(img, scale, 1)\n",
        "  return img\n",
        "\n",
        "class VideoWriter:\n",
        "  def __init__(self, filename, fps=30.0, **kw):\n",
        "    self.writer = None\n",
        "    self.params = dict(filename=filename, fps=fps, **kw)\n",
        "\n",
        "  def add(self, img):\n",
        "    img = np.asarray(img)\n",
        "    if self.writer is None:\n",
        "      h, w = img.shape[:2]\n",
        "      self.writer = FFMPEG_VideoWriter(size=(w, h), **self.params)\n",
        "    if img.dtype in [np.float32, np.float64]:\n",
        "      img = np.uint8(img.clip(0, 1)*255)\n",
        "    if len(img.shape) == 2:\n",
        "      img = np.repeat(img[..., None], 3, -1)\n",
        "    self.writer.write_frame(img)\n",
        "\n",
        "  def close(self):\n",
        "    if self.writer:\n",
        "      self.writer.close()\n",
        "\n",
        "  def __enter__(self):\n",
        "    return self\n",
        "\n",
        "  def __exit__(self, *kw):\n",
        "    self.close()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR6I1JONmWBb"
      },
      "source": [
        "#@title Cellular Automata Parameters\n",
        "CHANNEL_N = 16        # Number of CA state channels\n",
        "TARGET_PADDING = 16   # Number of pixels used to pad the target image border\n",
        "TARGET_SIZE = 40\n",
        "BATCH_SIZE = 8\n",
        "POOL_SIZE = 1024\n",
        "CELL_FIRE_RATE = 0.5\n",
        "\n",
        "TARGET_EMOJI = \"🦎\" #@param {type:\"string\"}\n",
        "\n",
        "EXPERIMENT_TYPE = \"Regenerating\" #@param [\"Growing\", \"Persistent\", \"Regenerating\"]\n",
        "EXPERIMENT_MAP = {\"Growing\":0, \"Persistent\":1, \"Regenerating\":2}\n",
        "EXPERIMENT_N = EXPERIMENT_MAP[EXPERIMENT_TYPE]\n",
        "\n",
        "USE_PATTERN_POOL = [0, 1, 1][EXPERIMENT_N]\n",
        "DAMAGE_N = [0, 0, 3][EXPERIMENT_N]  # Number of patterns to damage in a batch"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCbPFbI_zosW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "c22d042e-cfcd-4a6e-bcb6-50729fd265b4"
      },
      "source": [
        "#@title CA Model and Utilities\n",
        "\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "\n",
        "def load_image(url, max_size=TARGET_SIZE):\n",
        "  r = requests.get(url)\n",
        "  img = PIL.Image.open(io.BytesIO(r.content))\n",
        "  img.thumbnail((max_size, max_size), PIL.Image.LANCZOS)\n",
        "  img = np.float32(img)/255.0\n",
        "  # premultiply RGB by Alpha\n",
        "  img[..., :3] *= img[..., 3:]\n",
        "  return img\n",
        "\n",
        "def load_emoji(emoji):\n",
        "  code = hex(ord(emoji))[2:].lower()\n",
        "  url = 'https://github.com/googlefonts/noto-emoji/blob/main/png/128/emoji_u%s.png?raw=true'%code\n",
        "  return load_image(url)\n",
        "\n",
        "\n",
        "def to_rgba(x):\n",
        "  return x[..., :4]\n",
        "\n",
        "def to_alpha(x):\n",
        "  return tf.clip_by_value(x[..., 3:4], 0.0, 1.0)\n",
        "\n",
        "def to_rgb(x):\n",
        "  # assume rgb premultiplied by alpha\n",
        "  rgb, a = x[..., :3], to_alpha(x)\n",
        "  return 1.0-a+rgb\n",
        "\n",
        "def get_living_mask(x):\n",
        "  alpha = x[:, :, :, 3:4]\n",
        "  return tf.nn.max_pool2d(alpha, 3, [1, 1, 1, 1], 'SAME') > 0.1\n",
        "\n",
        "def make_seed(size, n=1):\n",
        "  x = np.zeros([n, size, size, CHANNEL_N], np.float32)\n",
        "  x[:, size//2, size//2, 3:] = 1.0\n",
        "  return x\n",
        "\n",
        "\n",
        "class CAModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, channel_n=CHANNEL_N, fire_rate=CELL_FIRE_RATE):\n",
        "    super().__init__()\n",
        "    self.channel_n = channel_n\n",
        "    self.fire_rate = fire_rate\n",
        "\n",
        "    self.dmodel = tf.keras.Sequential([\n",
        "          Conv2D(128, 1, activation=tf.nn.relu),\n",
        "          Conv2D(self.channel_n, 1, activation=None,\n",
        "              kernel_initializer=tf.zeros_initializer),\n",
        "    ])\n",
        "\n",
        "    self(tf.zeros([1, 3, 3, channel_n]))  # dummy call to build the model\n",
        "\n",
        "  @tf.function\n",
        "  def perceive(self, x, angle=0.0):\n",
        "    identify = np.float32([0, 1, 0])\n",
        "    identify = np.outer(identify, identify)\n",
        "    dx = np.outer([1, 2, 1], [-1, 0, 1]) / 8.0  # Sobel filter\n",
        "    dy = dx.T\n",
        "    c, s = tf.cos(angle), tf.sin(angle)\n",
        "    kernel = tf.stack([identify, c*dx-s*dy, s*dx+c*dy], -1)[:, :, None, :]\n",
        "    kernel = tf.repeat(kernel, self.channel_n, 2)\n",
        "    y = tf.nn.depthwise_conv2d(x, kernel, [1, 1, 1, 1], 'SAME')\n",
        "    return y\n",
        "\n",
        "  @tf.function\n",
        "  def call(self, x, fire_rate=None, angle=0.0, step_size=1.0):\n",
        "    pre_life_mask = get_living_mask(x)\n",
        "\n",
        "    y = self.perceive(x, angle)\n",
        "    dx = self.dmodel(y)*step_size\n",
        "    if fire_rate is None:\n",
        "      fire_rate = self.fire_rate\n",
        "    update_mask = tf.random.uniform(tf.shape(x[:, :, :, :1])) <= fire_rate\n",
        "    x += dx * tf.cast(update_mask, tf.float32)\n",
        "\n",
        "    post_life_mask = get_living_mask(x)\n",
        "    life_mask = pre_life_mask & post_life_mask\n",
        "    return x * tf.cast(life_mask, tf.float32)\n",
        "\n",
        "\n",
        "CAModel().dmodel.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │           \u001b[38;5;34m6,272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m16\u001b[0m)               │           \u001b[38;5;34m2,064\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,064</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,336\u001b[0m (32.56 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,336</span> (32.56 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,336\u001b[0m (32.56 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,336</span> (32.56 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDX5HL7VLd0z"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeWf6HeTe8kM"
      },
      "source": [
        "#@title Train Utilities (SamplePool, Model Export, Damage)\n",
        "from google.protobuf.json_format import MessageToDict\n",
        "from tensorflow.python.framework import convert_to_constants\n",
        "\n",
        "class SamplePool:\n",
        "  def __init__(self, *, _parent=None, _parent_idx=None, **slots):\n",
        "    self._parent = _parent\n",
        "    self._parent_idx = _parent_idx\n",
        "    self._slot_names = slots.keys()\n",
        "    self._size = None\n",
        "    for k, v in slots.items():\n",
        "      if self._size is None:\n",
        "        self._size = len(v)\n",
        "      assert self._size == len(v)\n",
        "      setattr(self, k, np.asarray(v))\n",
        "\n",
        "  def sample(self, n):\n",
        "    idx = np.random.choice(self._size, n, False)\n",
        "    batch = {k: getattr(self, k)[idx] for k in self._slot_names}\n",
        "    batch = SamplePool(**batch, _parent=self, _parent_idx=idx)\n",
        "    return batch\n",
        "\n",
        "  def commit(self):\n",
        "    for k in self._slot_names:\n",
        "      getattr(self._parent, k)[self._parent_idx] = getattr(self, k)\n",
        "\n",
        "@tf.function\n",
        "def make_circle_masks(n, h, w):\n",
        "  x = tf.linspace(-1.0, 1.0, w)[None, None, :]\n",
        "  y = tf.linspace(-1.0, 1.0, h)[None, :, None]\n",
        "  center = tf.random.uniform([2, n, 1, 1], -0.5, 0.5)\n",
        "  r = tf.random.uniform([n, 1, 1], 0.1, 0.4)\n",
        "  x, y = (x-center[0])/r, (y-center[1])/r\n",
        "  mask = tf.cast(x*x+y*y < 1.0, tf.float32)\n",
        "  return mask\n",
        "\n",
        "def export_model(ca, base_fn):\n",
        "  ca.save_weights(base_fn)\n",
        "\n",
        "  cf = ca.call.get_concrete_function(\n",
        "      x=tf.TensorSpec([None, None, None, CHANNEL_N]),\n",
        "      fire_rate=tf.constant(0.5),\n",
        "      angle=tf.constant(0.0),\n",
        "      step_size=tf.constant(1.0))\n",
        "  cf = convert_to_constants.convert_variables_to_constants_v2(cf)\n",
        "  graph_def = cf.graph.as_graph_def()\n",
        "  graph_json = MessageToDict(graph_def)\n",
        "  graph_json['versions'] = dict(producer='1.14', minConsumer='1.14')\n",
        "  model_json = {\n",
        "      'format': 'graph-model',\n",
        "      'modelTopology': graph_json,\n",
        "      'weightsManifest': [],\n",
        "  }\n",
        "  with open(base_fn+'.json', 'w') as f:\n",
        "    json.dump(model_json, f)\n",
        "\n",
        "def generate_pool_figures(pool, step_i):\n",
        "  tiled_pool = tile2d(to_rgb(pool.x[:49]))\n",
        "  fade = np.linspace(1.0, 0.0, 72)\n",
        "  ones = np.ones(72)\n",
        "  tiled_pool[:, :72] += (-tiled_pool[:, :72] + ones[None, :, None]) * fade[None, :, None]\n",
        "  tiled_pool[:, -72:] += (-tiled_pool[:, -72:] + ones[None, :, None]) * fade[None, ::-1, None]\n",
        "  tiled_pool[:72, :] += (-tiled_pool[:72, :] + ones[:, None, None]) * fade[:, None, None]\n",
        "  tiled_pool[-72:, :] += (-tiled_pool[-72:, :] + ones[:, None, None]) * fade[::-1, None, None]\n",
        "  imwrite('train_log/%04d_pool.jpg'%step_i, tiled_pool)\n",
        "\n",
        "def visualize_batch(x0, x, step_i):\n",
        "  vis0 = np.hstack(to_rgb(x0).numpy())\n",
        "  vis1 = np.hstack(to_rgb(x).numpy())\n",
        "  vis = np.vstack([vis0, vis1])\n",
        "  imwrite('train_log/batches_%04d.jpg'%step_i, vis)\n",
        "  print('batch (before/after):')\n",
        "  imshow(vis)\n",
        "\n",
        "def plot_loss(loss_log):\n",
        "  pl.figure(figsize=(10, 4))\n",
        "  pl.title('Loss history (log10)')\n",
        "  pl.plot(np.log10(loss_log), '.', alpha=0.1)\n",
        "  pl.show()\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKlA50h0jlvl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "outputId": "971812b4-6c43-4d36-a08c-f9fa645baa34"
      },
      "source": [
        "#@title Choose Target Image { vertical-output: true}\n",
        "#url = 'https://github.com/google-research/self-organising-systems/blob/master/assets/growing_ca/planaria2_48.png?raw=true'\n",
        "#target_img = load_image(url, 48)\n",
        "\n",
        "target_img = load_emoji(TARGET_EMOJI)\n",
        "imshow(zoom(to_rgb(target_img), 2), fmt='png')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ak5rBmbxmHV7"
      },
      "source": [
        "#@title Initialize Training { vertical-output: true}\n",
        "\n",
        "p = TARGET_PADDING\n",
        "pad_target = tf.pad(target_img, [(p, p), (p, p), (0, 0)])\n",
        "h, w = pad_target.shape[:2]\n",
        "seed = np.zeros([h, w, CHANNEL_N], np.float32)\n",
        "seed[h//2, w//2, 3:] = 1.0\n",
        "\n",
        "def loss_f(x):\n",
        "  return tf.reduce_mean(tf.square(to_rgba(x)-pad_target), [-2, -3, -1])\n",
        "\n",
        "ca = CAModel()\n",
        "\n",
        "loss_log = []\n",
        "\n",
        "lr = 2e-3\n",
        "lr_sched = tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
        "    [2000], [lr, lr*0.1])\n",
        "trainer = tf.keras.optimizers.Adam(lr_sched)\n",
        "\n",
        "loss0 = loss_f(seed).numpy()\n",
        "pool = SamplePool(x=np.repeat(seed[None, ...], POOL_SIZE, 0))\n",
        "\n",
        "!mkdir -p train_log && rm -f train_log/*"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzP_vDchq0d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 861
        },
        "outputId": "aea0c9d2-97fa-409b-cf5a-0c658541cf8d"
      },
      "source": [
        "#@title Training Loop {vertical-output: true}\n",
        "\n",
        "@tf.function\n",
        "def train_step(x):\n",
        "  iter_n = tf.random.uniform([], 64, 96, tf.int32)\n",
        "  with tf.GradientTape() as g:\n",
        "    for i in tf.range(iter_n):\n",
        "      x = ca(x)\n",
        "    loss = tf.reduce_mean(loss_f(x))\n",
        "  grads = g.gradient(loss, ca.weights)\n",
        "  grads = [g/(tf.norm(g)+1e-8) for g in grads]\n",
        "  trainer.apply_gradients(zip(grads, ca.weights))\n",
        "  return x, loss\n",
        "\n",
        "for i in range(8000+1):\n",
        "  if USE_PATTERN_POOL:\n",
        "    batch = pool.sample(BATCH_SIZE)\n",
        "    x0 = batch.x\n",
        "    loss_rank = loss_f(x0).numpy().argsort()[::-1]\n",
        "    x0 = x0[loss_rank]\n",
        "    x0[:1] = seed\n",
        "    if DAMAGE_N:\n",
        "      damage = 1.0-make_circle_masks(DAMAGE_N, h, w).numpy()[..., None]\n",
        "      x0[-DAMAGE_N:] *= damage\n",
        "  else:\n",
        "    x0 = np.repeat(seed[None, ...], BATCH_SIZE, 0)\n",
        "\n",
        "  x, loss = train_step(x0)\n",
        "\n",
        "  if USE_PATTERN_POOL:\n",
        "    batch.x[:] = x\n",
        "    batch.commit()\n",
        "\n",
        "  step_i = len(loss_log)\n",
        "  loss_log.append(loss.numpy())\n",
        "\n",
        "  if step_i%10 == 0:\n",
        "    generate_pool_figures(pool, step_i)\n",
        "  if step_i%100 == 0:\n",
        "    clear_output()\n",
        "    visualize_batch(x0, x, step_i)\n",
        "    plot_loss(loss_log)\n",
        "    export_model(ca, 'train_log/%04d.weights.h5'%step_i)\n",
        "\n",
        "  print('\\r step: %d, log10(loss): %.3f'%(len(loss_log), np.log10(loss)), end='')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch (before/after):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The filename must end in `.weights.h5`. Received: filepath=train_log/0000",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-02bc2987e246>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mvisualize_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mplot_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mexport_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train_log/%04d'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mstep_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\r step: %d, log10(loss): %.3f'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-6e876c858512>\u001b[0m in \u001b[0;36mexport_model\u001b[0;34m(ca, base_fn)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexport_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m   \u001b[0mca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   cf = ca.call.get_concrete_function(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36msave_weights\u001b[0;34m(model, filepath, overwrite, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".weights.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0;34m\"The filename must end in `.weights.h5`. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34mf\"Received: filepath={filepath}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The filename must end in `.weights.h5`. Received: filepath=train_log/0000"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAscSKkRaFwp"
      },
      "source": [
        "# Figures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqvkfl9W4ODI"
      },
      "source": [
        "#@title Training Progress (Checkpoints)\n",
        "\n",
        "models = []\n",
        "for i in [100, 500, 1000, 4000]:\n",
        "  ca = CAModel()\n",
        "  ca.load_weights('train_log/%04d'%i)\n",
        "  models.append(ca)\n",
        "\n",
        "out_fn = 'train_steps_damage_%d.mp4'%DAMAGE_N\n",
        "x = np.zeros([len(models), 72, 72, CHANNEL_N], np.float32)\n",
        "x[..., 36, 36, 3:] = 1.0\n",
        "with VideoWriter(out_fn) as vid:\n",
        "  for i in tqdm.trange(500):\n",
        "    vis = np.hstack(to_rgb(x))\n",
        "    vid.add(zoom(vis, 2))\n",
        "    for ca, xk in zip(models, x):\n",
        "      xk[:] = ca(xk[None,...])[0]\n",
        "mvp.ipython_display(out_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeXZKb5v2gxj"
      },
      "source": [
        "#@title Training Progress (Batches)\n",
        "frames = sorted(glob.glob('train_log/batches_*.jpg'))\n",
        "mvp.ImageSequenceClip(frames, fps=10.0).write_videofile('batches.mp4')\n",
        "mvp.ipython_display('batches.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4JAbAJf6Alw"
      },
      "source": [
        "#@title Pool Contents\n",
        "frames = sorted(glob.glob('train_log/*_pool.jpg'))[:80]\n",
        "mvp.ImageSequenceClip(frames, fps=20.0).write_videofile('pool.mp4')\n",
        "mvp.ipython_display('pool.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyxeGm6dJX8D"
      },
      "source": [
        "## Pretrained Models and Figures\n",
        "\n",
        "Please run the cell below to download pretrained models that are used to generate the subsequent figures. The figures generated after this are generated using the pretrained CAs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiGl7S0E6-OA"
      },
      "source": [
        "!wget -O models.zip 'https://github.com/google-research/self-organising-systems/blob/master/assets/growing_ca/models.zip?raw=true'\n",
        "!unzip -oq models.zip\n",
        "\n",
        "EMOJI = '🦎😀💥👁🐠🦋🐞🕸🥨🎄'\n",
        "\n",
        "def get_model(emoji='🦋', fire_rate=0.5, use_pool=1, damage_n=3, run=0,\n",
        "              prefix='models/', output='model'):\n",
        "  path = prefix\n",
        "  assert fire_rate in [0.5, 1.0]\n",
        "  if fire_rate==0.5:\n",
        "    path += 'use_sample_pool_%d damage_n_%d '%(use_pool, damage_n)\n",
        "  elif fire_rate==1.0:\n",
        "    path += 'fire_rate_1.0 '\n",
        "  code = hex(ord(emoji))[2:].upper()\n",
        "  path += 'target_emoji_%s run_index_%d/08000'%(code, run)\n",
        "  assert output in ['model', 'json']\n",
        "  if output == 'model':\n",
        "    ca = CAModel(channel_n=16, fire_rate=fire_rate)\n",
        "    ca.load_weights(path)\n",
        "    return ca\n",
        "  elif output == 'json':\n",
        "    return open(path+'.json', 'r').read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyMms2wKwX9x"
      },
      "source": [
        "atlas = np.hstack([load_emoji(e) for e in EMOJI])\n",
        "imshow(atlas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqgtL5VpLEeL"
      },
      "source": [
        "#@title Teaser\n",
        "models = [get_model(emoji, run=1) for emoji in EMOJI]\n",
        "\n",
        "with VideoWriter('teaser.mp4') as vid:\n",
        "  x = np.zeros([len(EMOJI), 64, 64, CHANNEL_N], np.float32)\n",
        "  # grow\n",
        "  for i in tqdm.trange(200):\n",
        "    k = i//20\n",
        "    if i%20==0 and k<len(EMOJI):\n",
        "      x[k, 32, 32, 3:] = 1.0\n",
        "    vid.add(zoom(tile2d(to_rgb(x), 5), 2))\n",
        "    for ca, xk in zip(models, x):\n",
        "      xk[:] = ca(xk[None,...])[0]\n",
        "  # damage\n",
        "  mask = PIL.Image.new('L', (64*5, 64*2))\n",
        "  draw = PIL.ImageDraw.Draw(mask)\n",
        "  for i in tqdm.trange(400):\n",
        "    cx, r = i*3-20, 6\n",
        "    y1, y2 = 32+np.sin(i/5+np.pi)*8, 32+64+np.sin(i/5)*8\n",
        "    draw.rectangle((0, 0, 64*5, 64*2), fill=0)\n",
        "    draw.ellipse((cx-r, y1-r, cx+r, y1+r), fill=255)\n",
        "    draw.ellipse((cx-r, y2-r, cx+r, y2+r), fill=255)\n",
        "    x *= 1.0-(np.float32(mask).reshape(2, 64, 5, 64)\n",
        "        .transpose([0, 2, 1, 3]).reshape(10, 64, 64, 1))/255.0\n",
        "    if i<200 or i%2 == 0:\n",
        "      vid.add(zoom(tile2d(to_rgb(x), 5), 2))\n",
        "    for ca, xk in zip(models, x):\n",
        "      xk[:] = ca(xk[None,...])[0]\n",
        "  # fade out\n",
        "  last = zoom(tile2d(to_rgb(x), 5), 2)\n",
        "  for t in np.linspace(0, 1, 30):\n",
        "    vid.add(last*(1.0-t)+t)\n",
        "\n",
        "mvp.ipython_display('teaser.mp4', loop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4O4tzfe-GRJ7"
      },
      "source": [
        "#@title Unstable Patterns\n",
        "!wget -O slider.png 'https://github.com/google-research/self-organising-systems/raw/master/assets/growing_ca/slider.png?raw=true'\n",
        "\n",
        "import PIL.ImageFont\n",
        "from matplotlib import font_manager as fm\n",
        "font_fn = fm.findfont(fm.FontProperties())\n",
        "font = PIL.ImageFont.truetype(font_fn, 20)\n",
        "\n",
        "models = [get_model(ch, use_pool=0, damage_n=0) for ch in EMOJI]\n",
        "fn = 'unstable.mp4'\n",
        "with VideoWriter(fn) as vid:\n",
        "  x = np.zeros([len(EMOJI), 64, 64, CHANNEL_N], np.float32)\n",
        "  x[:, 32, 32, 3:] = 1.0\n",
        "  # grow\n",
        "  slider = PIL.Image.open(\"slider.png\")\n",
        "  for i in tqdm.trange(1000):\n",
        "    if i<200 or i%5 == 0:\n",
        "      vis = zoom(tile2d(to_rgb(x), 5), 4).clip(0, 1)\n",
        "      vis_extended = np.concatenate((vis, np.ones((164, vis.shape[1], 3))), axis=0)\n",
        "      im = np.uint8(vis_extended*255)\n",
        "      im = PIL.Image.fromarray(im)\n",
        "      im.paste(slider, box=(20, vis.shape[0]+20))\n",
        "      draw = PIL.ImageDraw.Draw(im)\n",
        "      p_x = (14 + (610/1000)*i)*2.0\n",
        "      draw.rectangle([p_x, vis.shape[0]+20+55, p_x+10, vis.shape[0]+20+82], fill=\"#434343bd\")\n",
        "      vid.add(np.uint8(im))\n",
        "    for ca, xk in zip(models, x):\n",
        "      xk[:] = ca(xk[None,...])[0]\n",
        "  # fade out\n",
        "  for t in np.linspace(0, 1, 30):\n",
        "    vid.add(vis_extended*(1.0-t)+t)\n",
        "\n",
        "mvp.ipython_display(fn, loop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CVR9MeYnjuY"
      },
      "source": [
        "#@title Rotation\n",
        "row_size = 4\n",
        "models_of_interest = [\"🦋\",\"🦎\",\"🐠\",\"😀\"]\n",
        "num_images = 16\n",
        "imgs = []\n",
        "start_angle = np.random.randint(13, 76)\n",
        "\n",
        "for i in np.arange(num_images):\n",
        "  ang = start_angle + i * np.random.randint(36, 111)\n",
        "  ang = ang/360.0 * 2 * np.pi\n",
        "  if i % row_size == 0:\n",
        "    ca = get_model(models_of_interest[i // row_size])\n",
        "  x = np.zeros([1, 56, 56, CHANNEL_N], np.float32)\n",
        "  x[:, 28, 28, 3:] = 1.0\n",
        "  for i in range(500):\n",
        "    ang = tf.constant(ang, tf.float32)\n",
        "    x = ca(x, angle=ang)\n",
        "  imgs.append(to_rgb(x)[0])\n",
        "# Assumes the result is a multiple of row_size\n",
        "assert len(imgs) % row_size == 0\n",
        "imgs = zip(*(iter(imgs),) * row_size)\n",
        "\n",
        "imgs_arr = np.concatenate([np.hstack(im_row) for im_row in imgs])\n",
        "vis = zoom(imgs_arr, 4)\n",
        "\n",
        "imshow(vis, fmt='png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5JRLGxX1dnX"
      },
      "source": [
        "#@title Regeneration (trained without damage)\n",
        "models = [get_model(ch, damage_n=0) for ch in '😀🦋🦎']\n",
        "with VideoWriter('regen1.mp4') as vid:\n",
        "  x = np.zeros([len(models), 5, 56, 56, CHANNEL_N], np.float32)\n",
        "  cx, cy = 28, 28\n",
        "  x[:, :, cy, cx, 3:] = 1.0\n",
        "  for i in tqdm.trange(2000):\n",
        "    if i == 200:\n",
        "      x[:, 0, cy:] = x[:, 1, :cy] = 0\n",
        "      x[:, 2, :, cx:] = x[:, 3, :, :cx] = 0\n",
        "      x[:, 4, cy-8:cy+8, cx-8:cx+8] = 0\n",
        "    vis = to_rgb(x)\n",
        "    vis = np.vstack([np.hstack(row) for row in vis])\n",
        "    vis = zoom(vis, 2)\n",
        "    if (i < 400 and i%2==0) or i%8 == 0:\n",
        "      vid.add(vis)\n",
        "    if i == 200:\n",
        "      for _ in range(29):\n",
        "        vid.add(vis)\n",
        "    for ca, row in zip(models, x):\n",
        "      row[:] = ca(row)\n",
        "\n",
        "mvp.ipython_display('regen1.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDzJM69u4_8p"
      },
      "source": [
        "#@title Regeneration (trained with damage)\n",
        "models = [get_model(ch, damage_n=3) for ch in '😀🦋🦎']\n",
        "with VideoWriter('regen2.mp4') as vid:\n",
        "  x = np.zeros([len(models), 5, 56, 56, CHANNEL_N], np.float32)\n",
        "  cx, cy = 28, 28\n",
        "  x[:, :, cy, cx, 3:] = 1.0\n",
        "  for i in tqdm.trange(2000):\n",
        "    if i == 200:\n",
        "      x[:, 0, cy:] = x[:, 1, :cy] = 0\n",
        "      x[:, 2, :, cx:] = x[:, 3, :, :cx] = 0\n",
        "      x[:, 4, cy-8:cy+8, cx-8:cx+8] = 0\n",
        "    vis = to_rgb(x)\n",
        "    vis = np.vstack([np.hstack(row) for row in vis])\n",
        "    vis = zoom(vis, 2)\n",
        "    if (i < 400 and i%2==0) or i%8 == 0:\n",
        "      vid.add(vis)\n",
        "    if i == 200:\n",
        "      for _ in range(29):\n",
        "        vid.add(vis)\n",
        "    for ca, row in zip(models, x):\n",
        "      row[:] = ca(row)\n",
        "\n",
        "mvp.ipython_display('regen2.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQ1u2MqFy7Ni"
      },
      "source": [
        "#@title Planarian\n",
        "!wget -O planarian.zip 'https://github.com/google-research/self-organising-systems/blob/master/assets/growing_ca/planarian.zip?raw=true'\n",
        "!unzip -oq planarian.zip -d planarian\n",
        "\n",
        "ca = CAModel()\n",
        "ca.load_weights('planarian/train_log/8000')\n",
        "\n",
        "x = np.zeros([1, 64, 96, CHANNEL_N], np.float32)\n",
        "x[:, 32, 48, 3:] = 1.0\n",
        "with VideoWriter('planarian.mp4', 30.0) as vid:\n",
        "  for i in range(400):\n",
        "    vid.add(zoom(to_rgb(x[0])))\n",
        "    x = ca(x, angle=np.pi/2.0)\n",
        "    if i==150:\n",
        "      x = x.numpy()\n",
        "      for k in range(24):\n",
        "        x[:,:24] = np.roll(x[:,:24], 1, 2)\n",
        "        x[:,-24:] = np.roll(x[:,-24:], -1, 2)\n",
        "        vid.add(zoom(to_rgb(x[0])))\n",
        "      for k in range(20):\n",
        "        vid.add(zoom(to_rgb(x[0])))\n",
        "\n",
        "mvp.ipython_display('planarian.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9M-oDuhea7bR"
      },
      "source": [
        "# Interactive Demos\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7ypa-b7_fTn"
      },
      "source": [
        "#@title TensorFlow.js Demo {run:\"auto\", vertical-output: true}\n",
        "#@markdown Select \"CHECKPOINT\" model to load the checkpoint created by running cells from the \"Training\" section of this notebook\n",
        "import IPython.display\n",
        "\n",
        "model = \"CHECKPOINT\"  #@param ['CHECKPOINT', '😀 1F600', '💥 1F4A5', '👁 1F441', '🦎 1F98E', '🐠 1F420', '🦋 1F98B', '🐞 1F41E', '🕸 1F578', '🥨 1F968', '🎄 1F384']\n",
        "model_type = '3 regenerating'  #@param ['1 naive', '2 persistent', '3 regenerating']\n",
        "\n",
        "#@markdown Shift-click to seed the pattern\n",
        "\n",
        "if model != 'CHECKPOINT':\n",
        "  code = model.split(' ')[1]\n",
        "  emoji = chr(int(code, 16))\n",
        "  experiment_i = int(model_type.split()[0])-1\n",
        "  use_pool = (0, 1, 1)[experiment_i]\n",
        "  damage_n = (0, 0, 3)[experiment_i]\n",
        "  model_str = get_model(emoji, use_pool=use_pool, damage_n=damage_n, output='json')\n",
        "else:\n",
        "  last_checkpoint_fn = sorted(glob.glob('train_log/*.json'))[-1]\n",
        "  model_str = open(last_checkpoint_fn).read()\n",
        "\n",
        "data_js = '''\n",
        "  window.GRAPH_URL = URL.createObjectURL(new Blob([`%s`], {type: 'application/json'}));\n",
        "'''%(model_str)\n",
        "\n",
        "display(IPython.display.Javascript(data_js))\n",
        "\n",
        "\n",
        "IPython.display.HTML('''\n",
        "<script src=\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@2.3.0/dist/tf.min.js\"></script>\n",
        "\n",
        "<canvas id='canvas' style=\"border: 1px solid black; image-rendering: pixelated;\"></canvas>\n",
        "\n",
        "<script>\n",
        "  \"use strict\";\n",
        "\n",
        "  const sleep = (ms)=>new Promise(resolve => setTimeout(resolve, ms));\n",
        "\n",
        "  const parseConsts = model_graph=>{\n",
        "    const dtypes = {'DT_INT32':['int32', 'intVal', Int32Array],\n",
        "                    'DT_FLOAT':['float32', 'floatVal', Float32Array]};\n",
        "\n",
        "    const consts = {};\n",
        "    model_graph.modelTopology.node.filter(n=>n.op=='Const').forEach((node=>{\n",
        "      const v = node.attr.value.tensor;\n",
        "      const [dtype, field, arrayType] = dtypes[v.dtype];\n",
        "      if (!v.tensorShape.dim) {\n",
        "        consts[node.name] = [tf.scalar(v[field][0], dtype)];\n",
        "      } else {\n",
        "        // if there is a 0-length dimension, the exported graph json lacks \"size\"\n",
        "        const shape = v.tensorShape.dim.map(d=>(!d.size) ? 0 : parseInt(d.size));\n",
        "        let arr;\n",
        "        if (v.tensorContent) {\n",
        "          const data = atob(v.tensorContent);\n",
        "          const buf = new Uint8Array(data.length);\n",
        "          for (var i=0; i<data.length; ++i) {\n",
        "            buf[i] = data.charCodeAt(i);\n",
        "          }\n",
        "          arr = new arrayType(buf.buffer);\n",
        "        } else {\n",
        "          const size = shape.reduce((a, b)=>a*b);\n",
        "          arr = new arrayType(size);\n",
        "          if (size) {\n",
        "            arr.fill(v[field][0]);\n",
        "          }\n",
        "        }\n",
        "        consts[node.name] = [tf.tensor(arr, shape, dtype)];\n",
        "      }\n",
        "    }));\n",
        "    return consts;\n",
        "  }\n",
        "\n",
        "  const run = async ()=>{\n",
        "    const r = await fetch(GRAPH_URL);\n",
        "    const consts = parseConsts(await r.json());\n",
        "\n",
        "    const model = await tf.loadGraphModel(GRAPH_URL);\n",
        "    Object.assign(model.weights, consts);\n",
        "\n",
        "    let seed = new Array(16).fill(0).map((x, i)=>i<3?0:1);\n",
        "    seed = tf.tensor(seed, [1, 1, 1, 16]);\n",
        "\n",
        "    const D = 96;\n",
        "    const initState = tf.tidy(()=>{\n",
        "      const D2 = D/2;\n",
        "      const a = seed.pad([[0, 0], [D2-1, D2], [D2-1, D2], [0,0]]);\n",
        "      return a;\n",
        "    });\n",
        "\n",
        "    const state = tf.variable(initState);\n",
        "    const [_, h, w, ch] = state.shape;\n",
        "\n",
        "    const damage = (x, y, r)=>{\n",
        "      tf.tidy(()=>{\n",
        "        const rx = tf.range(0, w).sub(x).div(r).square().expandDims(0);\n",
        "        const ry = tf.range(0, h).sub(y).div(r).square().expandDims(1);\n",
        "        const mask = rx.add(ry).greater(1.0).expandDims(2);\n",
        "        state.assign(state.mul(mask));\n",
        "      });\n",
        "    }\n",
        "\n",
        "    const plantSeed = (x, y)=>{\n",
        "      const x2 = w-x-seed.shape[2];\n",
        "      const y2 = h-y-seed.shape[1];\n",
        "      if (x<0 || x2<0 || y2<0 || y2<0)\n",
        "        return;\n",
        "      tf.tidy(()=>{\n",
        "        const a = seed.pad([[0, 0], [y, y2], [x, x2], [0,0]]);\n",
        "        state.assign(state.add(a));\n",
        "      });\n",
        "    }\n",
        "\n",
        "    const scale = 4;\n",
        "\n",
        "    const canvas = document.getElementById('canvas');\n",
        "    const ctx = canvas.getContext('2d');\n",
        "    canvas.width = w;\n",
        "    canvas.height = h;\n",
        "    canvas.style.width = `${w*scale}px`;\n",
        "    canvas.style.height = `${h*scale}px`;\n",
        "\n",
        "    canvas.onmousedown = e=>{\n",
        "      const x = Math.floor(e.clientX/scale);\n",
        "        const y = Math.floor(e.clientY/scale);\n",
        "        if (e.buttons == 1) {\n",
        "          if (e.shiftKey) {\n",
        "            plantSeed(x, y);\n",
        "          } else {\n",
        "            damage(x, y, 8);\n",
        "          }\n",
        "        }\n",
        "    }\n",
        "    canvas.onmousemove = e=>{\n",
        "      const x = Math.floor(e.clientX/scale);\n",
        "      const y = Math.floor(e.clientY/scale);\n",
        "      if (e.buttons == 1 && !e.shiftKey) {\n",
        "        damage(x, y, 8);\n",
        "      }\n",
        "    }\n",
        "\n",
        "    function step() {\n",
        "      tf.tidy(()=>{\n",
        "        state.assign(model.execute(\n",
        "            {x:state, fire_rate:tf.tensor(0.5),\n",
        "            angle:tf.tensor(0.0), step_size:tf.tensor(1.0)}, ['Identity']));\n",
        "      });\n",
        "    }\n",
        "\n",
        "    function render() {\n",
        "      step();\n",
        "\n",
        "      const imageData = tf.tidy(()=>{\n",
        "        const rgba = state.slice([0, 0, 0, 0], [-1, -1, -1, 4]);\n",
        "        const a = state.slice([0, 0, 0, 3], [-1, -1, -1, 1]);\n",
        "        const img = tf.tensor(1.0).sub(a).add(rgba).mul(255);\n",
        "        const rgbaBytes = new Uint8ClampedArray(img.dataSync());\n",
        "        return new ImageData(rgbaBytes, w, h);\n",
        "      });\n",
        "      ctx.putImageData(imageData, 0, 0);\n",
        "\n",
        "      requestAnimationFrame(render);\n",
        "    }\n",
        "    render();\n",
        "  }\n",
        "  run();\n",
        "\n",
        "</script>\n",
        "''')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POma99rMIfV4"
      },
      "source": [
        "#@title WebGL Demo\n",
        "\n",
        "#@markdown This code exports quantized models for the WebGL demo that is used in the article.\n",
        "#@markdown The demo code can be found at https://github.com/distillpub/post--growing-ca/blob/master/public/ca.js\n",
        "\n",
        "def pack_layer(weight, bias, outputType=np.uint8):\n",
        "  in_ch, out_ch = weight.shape\n",
        "  assert (in_ch%4==0) and (out_ch%4==0) and (bias.shape==(out_ch,))\n",
        "  weight_scale, bias_scale = 1.0, 1.0\n",
        "  if outputType == np.uint8:\n",
        "    weight_scale = 2.0*np.abs(weight).max()\n",
        "    bias_scale = 2.0*np.abs(bias).max()\n",
        "    weight = np.round((weight/weight_scale+0.5)*255)\n",
        "    bias = np.round((bias/bias_scale+0.5)*255)\n",
        "  packed = np.vstack([weight, bias[None,...]])\n",
        "  packed = packed.reshape(in_ch+1, out_ch//4, 4)\n",
        "  packed = outputType(packed)\n",
        "  packed_b64 = base64.b64encode(packed.tobytes()).decode('ascii')\n",
        "  return {'data_b64': packed_b64, 'in_ch': in_ch, 'out_ch': out_ch,\n",
        "          'weight_scale': weight_scale, 'bias_scale': bias_scale,\n",
        "          'type': outputType.__name__}\n",
        "\n",
        "def export_ca_to_webgl_demo(ca, outputType=np.uint8):\n",
        "  # reorder the first layer inputs to meet webgl demo perception layout\n",
        "  chn = ca.channel_n\n",
        "  w1 = ca.weights[0][0, 0].numpy()\n",
        "  w1 = w1.reshape(chn, 3, -1).transpose(1, 0, 2).reshape(3*chn, -1)\n",
        "  layers = [\n",
        "      pack_layer(w1, ca.weights[1].numpy(), outputType),\n",
        "      pack_layer(ca.weights[2][0, 0].numpy(), ca.weights[3].numpy(), outputType)\n",
        "  ]\n",
        "  return json.dumps(layers)\n",
        "\n",
        "with zipfile.ZipFile('webgl_models8.zip', 'w') as zf:\n",
        "  for e in EMOJI:\n",
        "    zf.writestr('ex1_%s.json'%e, export_ca_to_webgl_demo(get_model(e, use_pool=0, damage_n=0)))\n",
        "    run = 1 if e in '😀🕸' else 0  # select runs that happen to quantize better\n",
        "    zf.writestr('ex2_%s.json'%e, export_ca_to_webgl_demo(get_model(e, use_pool=1, damage_n=0, run=run)))\n",
        "    run = 1 if e in '🦎' else 0    # select runs that happen to quantize better\n",
        "    zf.writestr('ex3_%s.json'%e, export_ca_to_webgl_demo(get_model(e, use_pool=1, damage_n=3, run=run)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}